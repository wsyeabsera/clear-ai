NODE_ENV=development
PORT=3001
API_URL=http://localhost:3001

# LLM Provider API Keys
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo

OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral:latest

MISTRAL_API_KEY=your_mistral_api_key_here
MISTRAL_MODEL=mistral-small-latest

GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.1-8b-instant

# Langfuse Configuration
LANGFUSE_PUBLIC_KEY=your_langfuse_public_key_here
LANGFUSE_SECRET_KEY=your_langfuse_secret_key_here
LANGFUSE_BASE_URL=https://cloud.langfuse.com

# Memory System Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_neo4j_password
NEO4J_DATABASE=neo4j

PINECONE_API_KEY=your_pinecone_api_key
PINECONE_ENVIRONMENT=your_pinecone_environment
PINECONE_INDEX_NAME=clear-ai-memories

MEMORY_EMBEDDING_MODEL=nomic-embed-text
MEMORY_EMBEDDING_DIMENSIONS=768

# Semantic Extraction Configuration
SEMANTIC_EXTRACTION_ENABLED=true
SEMANTIC_EXTRACTION_MIN_CONFIDENCE=0.7
SEMANTIC_EXTRACTION_MAX_CONCEPTS=3
SEMANTIC_EXTRACTION_RELATIONSHIPS=true
SEMANTIC_EXTRACTION_CATEGORIES=AI,Technology,Programming,Science,General
SEMANTIC_EXTRACTION_BATCH_SIZE=5
